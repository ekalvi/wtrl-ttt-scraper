# WTRL TTT Scraper

## Project Overview
The **WTRL TTT Scraper** is a Python-based project designed to scrape, process, and visualize time trial results from the WTRL website. It provides detailed data analysis for multiple teams and riders, generates dashboards with sortable tables and charts, and outputs static HTML files.

The results are found here (requires a WTRL account):  
ðŸ”— [WTRL TTT Results](https://www.wtrl.racing/ttt-results/)

---

## Features
- Fetches and parses race data from the WTRL website.
- Supports **multiple clubs** with multiple teams and aliases.
- Outputs sortable and filterable DataTables with visualizations.
- Generates **static HTML dashboards** for each team and an index for each club.
- Files can be hosted on [Netlify](https://www.netlify.com/) or similar static hosting platforms.

---

## Setup and Configuration

### **1. Install Dependencies**
- Ensure you have **Python 3.8 or higher** installed.
- Install required packages using:
  ```bash
  pip install -r requirements.txt
  ```

### **2. Configuration**
- A configuration file named `config.secret.json` is required in the project root.
- Start by copying the template:
  ```bash
  cp config.json config.secret.json
  ```
- **Configuration Format** (`config.secret.json`):
  ```json
  {
    "netlify_auth_token": "your_global_netlify_auth_token",
    "wtrl_sid": "your_wtrl_sid",
    "wtrl_ouid": "your_wtrl_ouid",
    "ctoken": "your_ctoken",
    "clubs": [
      {
        "club_name": "Waterloo Cycling Club",
        "site_id": "your_wcc_site_id",
        "teams": [
          {
            "team_name": "Waterloo Ones",
            "aliases": ["WCC Butter Tarts"]
          },
          {
            "team_name": "Waterloo Twos",
            "aliases": ["WCC Canucks"]
          }
        ]
      },
      {
        "club_name": "SISU Racing",
        "site_id": "your_sisu_site_id",
        "teams": [
          {
            "team_name": "SISU Racing Grit",
            "aliases": []
          },
          {
            "team_name": "SISU Racing Mokki",
            "aliases": []
          }
        ]
      }
    ]
  }
  ```

---

### **3. Extract Required Tokens**
- Running `main.py` will open a browser for you to log in to WTRL.  
  The tokens will automatically be extracted and inserted into `config.secret.json`.  
- **[Optional] Manually extract tokens using Developer Tools:**
  - **`wtrl_sid`** and **`wtrl_ouid`**: Found under `Application > Cookies > https://www.wtrl.racing`.
  - **`ctoken`**: Found under `Application > Session Storage > https://www.wtrl.racing` (refresh after logout).

---

## File Structure
```
WTRL-TTT-Scraper/
â”œâ”€â”€ cache/                   # Cached race results in JSON format
â”œâ”€â”€ results/                 # Generated HTML files for clubs and teams
â”‚   â”œâ”€â”€ waterloo-cycling-club/  # Results for Waterloo Cycling Club
â”‚   â”‚   â”œâ”€â”€ index.html         # Index for all WCC teams
â”‚   â”‚   â”œâ”€â”€ waterloo-ones.html # Results for Waterloo Ones
â”‚   â”‚   â”œâ”€â”€ waterloo-twos.html # Results for Waterloo Twos
â”‚   â”œâ”€â”€ sisu-racing/           # Results for SISU Racing
â”‚   â”‚   â”œâ”€â”€ index.html         # Index for SISU teams
â”‚   â”‚   â”œâ”€â”€ sisu-racing-grit.html  # Results for SISU Racing Grit
â”‚   â”‚   â”œâ”€â”€ sisu-racing-mokki.html # Results for SISU Racing Mokki
â”œâ”€â”€ wtrl/                    # Core package for the scraper
â”‚   â”œâ”€â”€ __init__.py          # Package init
â”‚   â”œâ”€â”€ scrape.py            # Scraping logic
â”‚   â”œâ”€â”€ render.py            # HTML rendering
â”‚   â”œâ”€â”€ models.py            # Data models
â”‚   â”œâ”€â”€ format.py            # Formatting utilities
â”‚   â”œâ”€â”€ parse.py             # Parsing utilities
â”‚   â”œâ”€â”€ calculate.py         # Calculations (e.g., percentiles)
â”œâ”€â”€ main.py                  # Entry point for the scraper
â”œâ”€â”€ config.py                 # Configuration logic
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Documentation
â”œâ”€â”€ LICENSE.md                # License file
â””â”€â”€ scripts.sh                # Utility scripts for automation
```

---

## **Usage**

### **1. Run the Scraper**
- Execute the main script to scrape data and generate results:
  ```bash
  python main.py
  ```
- The script will automatically:
  - Load **`config.secret.json`** (or fallback to `config.json`).
  - Authenticate with WTRL.
  - Scrape **all configured clubs and teams**.
  - Save results in **`results/[club_name]/`**.

### **2. Access Results**
- Generated HTML files will be saved in the **`results/` directory**, structured per club:
  - **`results/[club_name]/index.html`** â†’ Central index for the club.
  - **`results/[club_name]/[team_name].html`** â†’ Individual dashboards.

### **3. Publish Results**
- Host the `results/` directory on a **static hosting service**:
  - **[Netlify](https://www.netlify.com/)** â†’ Drag and drop `results/` into Netlifyâ€™s UI.
  - **[GitHub Pages](https://pages.github.com/)** â†’ Push `results/` to GitHub and enable Pages.
  
### **4. Format Code**
- Ensure Python code is formatted using **[Black](https://black.readthedocs.io/en/latest/)**
  ```bash
  black .
  ```

---

## **Notes**
- Make sure your **`config.secret.json`** file is excluded from version control (`.gitignore`).
- The **`cache/` directory** stores JSON-formatted race results for caching.
- Keep your **extracted tokens (`wtrl_sid`, `wtrl_ouid`, `ctoken`) secure**, as they are tied to your account.

---

## **Contributing**
Feel free to **submit issues or pull requests** to improve the project. Contributions are always welcome! ðŸš€
